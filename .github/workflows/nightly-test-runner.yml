name: Nightly Test Runner

on:
  schedule:
    # Run every night at 2 AM UTC
    - cron: '0 2 * * *'
  workflow_dispatch:
    inputs:
      create_issues:
        description: 'Create GitHub issues for failed tests'
        required: false
        default: 'true'
        type: choice
        options:
          - 'true'
          - 'false'

jobs:
  run-tests:
    runs-on: ubuntu-latest
    outputs:
      test_exit_code: ${{ steps.test-runner.outputs.test_exit_code }}
    permissions:
      contents: read
      issues: write

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '18'
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Build project
        run: npm run build

      - name: Run tests and capture results
        id: test-runner
        continue-on-error: true
        run: |
          # Create test results directory
          mkdir -p test-results

          # Run tests with JSON reporter (vitest syntax), excluding e2e tests
          npm test -- --reporter=json --outputFile=test-results/results.json tests/ --exclude='**/*.e2e.test.ts' 2>&1 | tee test-results/output.log
          TEST_EXIT_CODE=${PIPESTATUS[0]}

          # Save exit code for later
          echo "test_exit_code=${TEST_EXIT_CODE}" >> $GITHUB_OUTPUT

          # Parse test results if JSON was generated
          if [ -f test-results/results.json ]; then
            # Vitest JSON format: count test results from testResults array
            TOTAL_TESTS=$(jq '[.testResults[]?.assertionResults[]?] | length' test-results/results.json 2>/dev/null || echo "0")
            FAILED_TESTS=$(jq '[.testResults[]?.assertionResults[]? | select(.status == "failed")] | length' test-results/results.json 2>/dev/null || echo "0")
            PASSED_TESTS=$(jq '[.testResults[]?.assertionResults[]? | select(.status == "passed")] | length' test-results/results.json 2>/dev/null || echo "0")

            echo "total_tests=${TOTAL_TESTS}" >> $GITHUB_OUTPUT
            echo "failed_tests=${FAILED_TESTS}" >> $GITHUB_OUTPUT
            echo "passed_tests=${PASSED_TESTS}" >> $GITHUB_OUTPUT

            echo "Test Summary: ${PASSED_TESTS}/${TOTAL_TESTS} passed, ${FAILED_TESTS} failed"
          else
            echo "No JSON results generated, checking output log..."
            # Try to extract info from output log
            grep -E "(PASS|FAIL|✓|✗)" test-results/output.log > test-results/test-summary.txt || true
          fi

          exit ${TEST_EXIT_CODE}

      - name: Upload test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-results-${{ github.run_number }}
          path: test-results/
          retention-days: 30

      - name: Create test summary comment
        if: always()
        run: |
          # Create a summary of the test results
          if [ -f test-results/results.json ]; then
            cat > test-results/summary.md << EOF
          ## 🧪 Nightly Test Results

          **Date:** $(date -u +"%Y-%m-%d %H:%M UTC")
          **Status:** ${{ steps.test-runner.outputs.test_exit_code == '0' && '✅ All tests passed' || '❌ Tests failed' }}

          ### Statistics
          - **Total Tests:** ${{ steps.test-runner.outputs.total_tests }}
          - **Passed:** ${{ steps.test-runner.outputs.passed_tests }}
          - **Failed:** ${{ steps.test-runner.outputs.failed_tests }}

          **Workflow:** [View Run](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }})
          EOF
          else
            cat > test-results/summary.md << EOF
          ## 🧪 Nightly Test Results

          **Date:** $(date -u +"%Y-%m-%d %H:%M UTC")
          **Status:** ${{ steps.test-runner.outputs.test_exit_code == '0' && '✅ Tests completed' || '❌ Tests failed' }}
          **Exit Code:** ${{ steps.test-runner.outputs.test_exit_code }}

          Test output has been captured in the artifacts.

          **Workflow:** [View Run](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }})
          EOF
          fi

          echo "Summary created at test-results/summary.md"

  claude-analyze-failures:
    needs: run-tests
    runs-on: ubuntu-latest
    if: needs.run-tests.outputs.test_exit_code != '0' && (github.event_name == 'schedule' || github.event.inputs.create_issues == 'true')
    permissions:
      contents: read
      issues: write
      id-token: write

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '18'

      - name: Download test results
        uses: actions/download-artifact@v4
        with:
          name: test-results-${{ github.run_number }}
          path: ./test-results

      - name: Configure gh CLI
        run: |
          echo "${{ secrets.GITHUB_TOKEN }}" | gh auth login --with-token
          gh auth status

      - name: Analyze failures and create issues with Claude Code
        uses: anthropics/claude-code-action@v1
        with:
          claude_code_oauth_token: ${{ secrets.CLAUDE_CODE_OAUTH_TOKEN }}
          claude_args: --allowedTools Bash(gh issue create:*),Bash(gh issue list:*),Bash(gh pr list:*),Read,Grep,Glob
          prompt: |
            I have test results from a nightly test run that failed. Please analyze the failures and create GitHub issues for test failures ONLY (not coverage issues).

            IMPORTANT: DO NOT create any markdown (.md) files. Only create GitHub issues using gh commands.

            Repository: ${{ github.repository }}
            Workflow Run: https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}
            Test Results: ./test-results/

            Instructions:
            1. FIRST: Check the number of open PRs with the label "test-failure-fix" using:
               gh pr list --label "test-failure-fix" --state open --json number --jq length
            2. If there are already 5 or more open PRs, STOP - do not create any issues
            3. Read the test results in ./test-results/ (check results.json, output.log, and any other files)
            4. Identify each distinct TEST FAILURE (not coverage gaps - only failing tests)
            5. For each failure or group of related failures, create a GitHub issue using 'gh issue create' ONLY if we're under the 5 PR cap
            6. Each issue should include:
               - Clear title: "Test Failure: [test name or description]"
               - The error message and stack trace
               - The test file and line number if available
               - Steps to reproduce if identifiable
               - Labels: "bug", "test-failure", "nightly-test"
               - Reference to this workflow run: https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}
               - **IMPORTANT**: Include "@test-fixer" in the issue body to trigger the auto-fix workflow
               - Note that this was detected by Claude Code's nightly test analysis
            7. If there are many similar failures, group them into one issue
            8. Prioritize based on:
               - Critical path tests
               - Number of affected tests
               - Type of failure (timeout, assertion, error)
            9. Keep track of how many issues you create - stop before you would create a 6th PR (since each issue triggers a PR)

            Before creating issues, check if similar issues already exist using:
            gh issue list --label "test-failure" --state open

            The gh CLI is already authenticated. Start by checking the PR cap, then examining the test results.

      - name: Create summary issue for multiple failures
        if: always()
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          GITHUB_REPOSITORY: ${{ github.repository }}
          GITHUB_RUN_URL: "https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}"
        run: |
          # Count existing issues created in this run
          ISSUES_CREATED=$(gh issue list --label "nightly-test" --state open --json createdAt --jq "[.[] | select(.createdAt > \"$(date -u -d '5 minutes ago' --iso-8601)\")]  | length")

          if [ "$ISSUES_CREATED" -gt 3 ]; then
            echo "Multiple issues created. Adding summary issue..."

            gh issue create \
              --title "Nightly Test Run: Multiple Failures Detected" \
              --body "The nightly test run detected multiple test failures and created ${ISSUES_CREATED} individual issues.

              **Workflow Run:** ${GITHUB_RUN_URL}
              **Date:** $(date -u +"%Y-%m-%d %H:%M UTC")

              ### Related Issues
              See all issues with label: [nightly-test](https://github.com/${GITHUB_REPOSITORY}/issues?q=is%3Aissue+is%3Aopen+label%3Anightly-test)

              ### Next Steps
              1. Review individual test failure issues
              2. Prioritize critical failures
              3. Consider disabling flaky tests temporarily

              _Created by Claude Code automation_" \
              --label "test-failure" \
              --label "nightly-test"
          fi